# generate_entities.py
import os
import random
import pandas as pd
from faker import Faker
from datetime import datetime, timedelta
from utils.csv_writer import write_csv
from utils.id_tracker import save_ids, load_ids

fake = Faker('vi_VN')

BASE_DIR = os.path.dirname(__file__)
OUTPUT_DIR = os.path.join(BASE_DIR, "data", "entities")
INPUT_DIR = os.path.join(BASE_DIR, "data", "catalogs")
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ============================================================
# üîß H√ÄM D√ôNG CHUNG
# ============================================================

def next_ids(table_name, n):
    """T·∫°o danh s√°ch ID m·ªõi, n·ªëi ti·∫øp v·ªõi ID c≈©."""
    prev = load_ids(table_name)
    start = max(prev) + 1 if prev else 1
    ids = list(range(start, start + n))
    save_ids(table_name, ids)
    return ids

def ensure_catalogs_exist(tables):
    base_dir = os.path.dirname(__file__)
    catalogs_dir = os.path.join(base_dir, "data", "catalogs")

    for table in tables:
        path = os.path.join(catalogs_dir, f"{table}.csv")
        if not os.path.exists(path):
            raise Exception(f"‚ö†Ô∏è Thi·∫øu d·ªØ li·ªáu danh m·ª•c: {table}. H√£y ch·∫°y generate_catalogs.py tr∆∞·ªõc.")

def load_unit_map():
    file_path = os.path.join(INPUT_DIR, "Product_Units.csv")
    df = pd.read_csv(file_path)
    return {row["UnitName"]: row["UnitID"] for _, row in df.iterrows()}


# ============================================================
# üß© H√ÄM SINH D·ªÆ LI·ªÜU
# ============================================================

def generate_products(n=15000):
    ensure_catalogs_exist(["Product_Categories", "Product_Units", "Product_Status"])
    category_ids = load_ids("Product_Categories")
    unit_ids = load_ids("Product_Units")
    status_ids = load_ids("Product_Status")

    # === ƒê·ªçc t√™n danh m·ª•c v√† map ID -> T√™n
    file_path = os.path.join(INPUT_DIR, "Product_Categories.csv")
    df = pd.read_csv(file_path)
    category_map = dict(zip(df["CategoryID"], df["CategoryName"]))

    # === ƒê·ªçc UnitName -> UnitID map
    unit_map = load_unit_map()

    # === T·ª´ kh√≥a ƒë·∫∑c tr∆∞ng t·ª´ng danh m·ª•c
    category_keywords = {
        "ƒê·ªì u·ªëng": ["N∆∞·ªõc su·ªëi", "Tr√† xanh", "C√† ph√™", "Soda", "S·ªØa ƒë·∫≠u n√†nh", "N∆∞·ªõc ng·ªçt", "Tr√† s·ªØa"],
        "B√°nh k·∫πo": ["B√°nh quy", "Snack", "K·∫πo d·∫ªo", "Socola", "B√°nh x·ªëp", "B√°nh g·∫°o"],
        "Th·ª±c ph·∫©m t∆∞∆°i s·ªëng": ["Th·ªãt heo", "Th·ªãt b√≤", "C√° h·ªìi", "T√¥m", "Rau mu·ªëng", "C√† r·ªët", "Chu·ªëi", "Cam"],
        "Th·ª±c ph·∫©m kh√¥": ["G·∫°o", "M√¨ g√≥i", "ƒê·∫≠u xanh", "ƒê·∫≠u ƒë·ªè", "Ng≈© c·ªëc", "B√∫n kh√¥", "Mi·∫øn"],
        "Gia v·ªã": ["Mu·ªëi", "ƒê∆∞·ªùng", "B·ªôt ng·ªçt", "N∆∞·ªõc m·∫Øm", "N∆∞·ªõc t∆∞∆°ng", "D·∫ßu ƒÉn", "Ti√™u", "T∆∞∆°ng ·ªõt"],
        "ƒê·ªì gia d·ª•ng": ["N·ªìi inox", "Dao b·∫øp", "Ch·∫£o ch·ªëng d√≠nh", "Ch√©n s·ª©", "Ly th·ªßy tinh", "Dƒ©a nh·ª±a"],
        "ChƒÉm s√≥c c√° nh√¢n": ["D·∫ßu g·ªôi", "S·ªØa t·∫Øm", "Kem ƒë√°nh rƒÉng", "B√†n ch·∫£i", "N∆∞·ªõc hoa", "LƒÉn kh·ª≠ m√πi"],
        "ChƒÉm s√≥c nh√† c·ª≠a": ["N∆∞·ªõc lau s√†n", "N∆∞·ªõc r·ª≠a ch√©n", "B·ªôt gi·∫∑t", "N∆∞·ªõc x·ªãt ph√≤ng", "T√∫i r√°c"],
        "Th·ª±c ph·∫©m ƒë√¥ng l·∫°nh": ["X√∫c x√≠ch", "Ch·∫£ gi√≤", "C√° vi√™n", "T√¥m ƒë√¥ng l·∫°nh", "G√† vi√™n", "B√°nh bao"],
        "S·ªØa v√† s·∫£n ph·∫©m t·ª´ s·ªØa": ["S·ªØa t∆∞∆°i", "S·ªØa chua", "Ph√¥ mai", "B∆°", "S·ªØa ƒë·∫∑c"]
    }

    # === ƒê∆°n v·ªã ph√π h·ª£p v·ªõi t·ª´ng danh m·ª•c
    category_units = {
        "ƒê·ªì u·ªëng": ["Chai", "L√≠t", "H·ªôp"],
        "B√°nh k·∫πo": ["G√≥i", "H·ªôp", "C√°i"],
        "Th·ª±c ph·∫©m t∆∞∆°i s·ªëng": ["Kg", "Gram"],
        "Th·ª±c ph·∫©m kh√¥": ["Kg", "G√≥i"],
        "Gia v·ªã": ["Chai", "G√≥i", "Gram"],
        "ƒê·ªì gia d·ª•ng": ["C√°i", "B·ªô"],
        "ChƒÉm s√≥c c√° nh√¢n": ["Chai", "H·ªôp", "Tu√Ωp"],
        "ChƒÉm s√≥c nh√† c·ª≠a": ["Chai", "T√∫i", "H·ªôp"],
        "Th·ª±c ph·∫©m ƒë√¥ng l·∫°nh": ["G√≥i", "H·ªôp", "Kg"],
        "S·ªØa v√† s·∫£n ph·∫©m t·ª´ s·ªØa": ["H·ªôp", "L√≠t", "Chai"]
    }

    ids = next_ids("Products", n)
    data = []

    for pid in ids:
        cat_id = random.choice(category_ids)
        cat_name = category_map.get(cat_id, "Kh√°c")

        # T√™n s·∫£n ph·∫©m theo danh m·ª•c
        keywords = category_keywords.get(cat_name, [fake.word().capitalize()])
        product_name = random.choice(keywords)

        # ƒê∆°n v·ªã ph√π h·ª£p
        possible_units = category_units.get(cat_name, ["C√°i"])
        unit_name = random.choice(possible_units)
        unit_id = unit_map.get(unit_name, random.choice(unit_ids))

        # Th√™m th∆∞∆°ng hi·ªáu ƒë·ªÉ ƒëa d·∫°ng
        brand = fake.company().split()[0]
        full_name = f"{product_name} {brand}"

        data.append({
            "ProductID": pid,
            "ProductName": full_name,
            "CategoryID": cat_id,
            "UnitID": unit_id,
            "StatusID": random.choice(status_ids),
            "Description": fake.sentence(nb_words=10),
            "CreatedDate": fake.date_time_between(start_date="-2y", end_date="now").strftime("%Y-%m-%d %H:%M:%S")
        })

    write_csv(
        os.path.join(OUTPUT_DIR, "Products.csv"),
        fieldnames=list(data[0].keys()),
        data_rows=data
    )

    print(f"[OK] Products ({n} h√†ng)")



def generate_employees(n=3500):
    ensure_catalogs_exist(["Employee_Types", "Employee_Status"])
    type_ids = load_ids("Employee_Types")
    status_ids = load_ids("Employee_Status")

    ids = next_ids("Employees", n)
    data = []
    for eid in ids:
        data.append({
            "EmployeeID": eid,
            "FullName": fake.name(),
            "TypeID": random.choice(type_ids),
            "StatusID": random.choice(status_ids),
            "HireDate": fake.date_between(start_date="-3y", end_date="today").strftime("%Y-%m-%d"),
            "Email": fake.email(),
            "Phone": fake.phone_number()
        })

    write_csv(os.path.join(OUTPUT_DIR, "Employees.csv"), list(data[0].keys()), data)

    print(f"[OK] Employees ({n} h√†ng)")

    

def generate_customers(n=300000):
    ensure_catalogs_exist(["Customer_Types", "Customer_Status"])
    type_ids = load_ids("Customer_Types")
    status_ids = load_ids("Customer_Status")

    ids = next_ids("Customers", n)
    data = []
    for cid in ids:
        data.append({
            "CustomerID": cid,
            "FullName": fake.name(),
            "TypeID": random.choice(type_ids),
            "StatusID": random.choice(status_ids),
            "Email": fake.email(),
            "Phone": fake.phone_number(),
            "RegistrationDate": fake.date_between(start_date="-2y", end_date="today").strftime("%Y-%m-%d")
        })

    write_csv(os.path.join(OUTPUT_DIR, "Customers.csv"), list(data[0].keys()), data)

    print(f"[OK] Customers ({n} h√†ng)")



def generate_branches(n=120):
    ensure_catalogs_exist(["Branch_Types", "Branch_Status"])
    type_ids = load_ids("Branch_Types")
    status_ids = load_ids("Branch_Status")

    ids = next_ids("Branches", n)
    data = []
    for bid in ids:
        city = getattr(fake, "city_name", fake.city)()
        data.append({
            "BranchID": bid,
            "BranchName": f"Chi nh√°nh {city}",
            "TypeID": random.choice(type_ids),
            "StatusID": random.choice(status_ids),
            "Address": fake.address().replace("\n", ", "),
            "Phone": fake.phone_number(),
            "Email": fake.email(),
            "CreatedDate": fake.date_between(start_date="-3y", end_date="today").strftime("%Y-%m-%d")
        })

    write_csv(os.path.join(OUTPUT_DIR, "Branches.csv"), list(data[0].keys()), data)

    print(f"[OK] Branches ({n} h√†ng)")



# ============================================================
# üöÄ MAIN
# ============================================================

def main():
    print("=== Sinh d·ªØ li·ªáu Entities ===")
    generate_products(n=15000)
    generate_employees(n=3500)
    generate_customers(n=300000)
    generate_branches(n=120)
    print("=== Ho√†n t·∫•t: Entities ƒë√£ ƒë∆∞·ª£c sinh ===")

if __name__ == "__main__":
    main()
