# 03. ETL Flow

## 1. M·ª•c ti√™u

T√†i li·ªáu m√¥ t·∫£ quy tr√¨nh ETL ƒë∆∞·ª£c s·ª≠ d·ª•ng trong d·ª± √°n Retail Database:

- Sinh d·ªØ li·ªáu b·∫±ng Python + Faker  
- Xu·∫•t ra file CSV  
- T·∫°o file SQL*Loader `.ctl`  
- T·∫°o script `.sh` / `.bat`  
- Chuy·ªÉn to√†n b·ªô file li√™n quan sang m√°y ·∫£o Oracle  
- Ch·∫°y `run_all_loaders.sh` ƒë·ªÉ n·∫°p d·ªØ li·ªáu v√†o DB  
- Qu·∫£n l√Ω log, badfile, discardfile

---

## 2. T·ªïng quan quy tr√¨nh ETL

Python (Faker)
‚Üì
CSV Files (.csv)
‚Üì
Control Files (.ctl)
‚Üì
Shell/Bat Scripts
‚Üì
Chuy·ªÉn sang m√°y ·∫£o (WinSCP)
‚Üì
run_all_loaders.sh
‚Üì
SQL*Loader
‚Üì
Oracle Database (OLTP)

---

## 3. M√¥i tr∆∞·ªùng th·ª±c hi·ªán

### 3.1 M√°y ph√°t tri·ªÉn (Local)
- Python 3.x  
- Faker  
- Xu·∫•t CSV  
- T·∫°o `.ctl`, `.sh`, `.bat`
- WinSCP
- MobaXterm
- SQL Developer

### 3.2 M√°y ·∫£o ch·∫°y Oracle
- Oracle Linux 8
- Oracle Database  
- SQL*Loader  
- Bash shell (ch·∫°y `run_all_loaders.sh`)

---

## 4. Sinh d·ªØ li·ªáu b·∫±ng Python (Faker)

V√≠ d·ª• sinh d·ªØ li·ªáu b·∫£ng **Products**:
```python
import os
import random
import pandas as pd
from faker import Faker
from datetime import datetime, timedelta
from utils.csv_writer import write_csv
from utils.id_tracker import save_ids, load_ids

fake = Faker('vi_VN')

BASE_DIR = os.path.dirname(__file__)
OUTPUT_DIR = os.path.join(BASE_DIR, "data", "entities")
INPUT_DIR = os.path.join(BASE_DIR, "data", "catalogs")
os.makedirs(OUTPUT_DIR, exist_ok=True)

def next_ids(table_name, n):
    """T·∫°o danh s√°ch ID m·ªõi, n·ªëi ti·∫øp v·ªõi ID c≈©."""
    prev = load_ids(table_name)
    start = max(prev) + 1 if prev else 1
    ids = list(range(start, start + n))
    save_ids(table_name, ids)
    return ids

def ensure_catalogs_exist(tables):
    base_dir = os.path.dirname(__file__)
    catalogs_dir = os.path.join(base_dir, "data", "catalogs")

    for table in tables:
        path = os.path.join(catalogs_dir, f"{table}.csv")
        if not os.path.exists(path):
            raise Exception(f"‚ö†Ô∏è Thi·∫øu d·ªØ li·ªáu danh m·ª•c: {table}. H√£y ch·∫°y generate_catalogs.py tr∆∞·ªõc.")

def load_unit_map():
    file_path = os.path.join(INPUT_DIR, "Product_Units.csv")
    df = pd.read_csv(file_path)
    return {row["UnitName"]: row["UnitID"] for _, row in df.iterrows()}

def generate_products(n=15000):
    ensure_catalogs_exist(["Product_Categories", "Product_Units", "Product_Status"])
    category_ids = load_ids("Product_Categories")
    unit_ids = load_ids("Product_Units")
    status_ids = load_ids("Product_Status")

    # === ƒê·ªçc t√™n danh m·ª•c v√† map ID -> T√™n
    file_path = os.path.join(INPUT_DIR, "Product_Categories.csv")
    df = pd.read_csv(file_path)
    category_map = dict(zip(df["CategoryID"], df["CategoryName"]))

    # === ƒê·ªçc UnitName -> UnitID map
    unit_map = load_unit_map()

    # === T·ª´ kh√≥a ƒë·∫∑c tr∆∞ng t·ª´ng danh m·ª•c
    category_keywords = {
        "ƒê·ªì u·ªëng": ["N∆∞·ªõc su·ªëi", "Tr√† xanh", "C√† ph√™", "Soda", "S·ªØa ƒë·∫≠u n√†nh", "N∆∞·ªõc ng·ªçt", "Tr√† s·ªØa"],
        "B√°nh k·∫πo": ["B√°nh quy", "Snack", "K·∫πo d·∫ªo", "Socola", "B√°nh x·ªëp", "B√°nh g·∫°o"],
        "Th·ª±c ph·∫©m t∆∞∆°i s·ªëng": ["Th·ªãt heo", "Th·ªãt b√≤", "C√° h·ªìi", "T√¥m", "Rau mu·ªëng", "C√† r·ªët", "Chu·ªëi", "Cam"],
        "Th·ª±c ph·∫©m kh√¥": ["G·∫°o", "M√¨ g√≥i", "ƒê·∫≠u xanh", "ƒê·∫≠u ƒë·ªè", "Ng≈© c·ªëc", "B√∫n kh√¥", "Mi·∫øn"],
        "Gia v·ªã": ["Mu·ªëi", "ƒê∆∞·ªùng", "B·ªôt ng·ªçt", "N∆∞·ªõc m·∫Øm", "N∆∞·ªõc t∆∞∆°ng", "D·∫ßu ƒÉn", "Ti√™u", "T∆∞∆°ng ·ªõt"],
        "ƒê·ªì gia d·ª•ng": ["N·ªìi inox", "Dao b·∫øp", "Ch·∫£o ch·ªëng d√≠nh", "Ch√©n s·ª©", "Ly th·ªßy tinh", "Dƒ©a nh·ª±a"],
        "ChƒÉm s√≥c c√° nh√¢n": ["D·∫ßu g·ªôi", "S·ªØa t·∫Øm", "Kem ƒë√°nh rƒÉng", "B√†n ch·∫£i", "N∆∞·ªõc hoa", "LƒÉn kh·ª≠ m√πi"],
        "ChƒÉm s√≥c nh√† c·ª≠a": ["N∆∞·ªõc lau s√†n", "N∆∞·ªõc r·ª≠a ch√©n", "B·ªôt gi·∫∑t", "N∆∞·ªõc x·ªãt ph√≤ng", "T√∫i r√°c"],
        "Th·ª±c ph·∫©m ƒë√¥ng l·∫°nh": ["X√∫c x√≠ch", "Ch·∫£ gi√≤", "C√° vi√™n", "T√¥m ƒë√¥ng l·∫°nh", "G√† vi√™n", "B√°nh bao"],
        "S·ªØa v√† s·∫£n ph·∫©m t·ª´ s·ªØa": ["S·ªØa t∆∞∆°i", "S·ªØa chua", "Ph√¥ mai", "B∆°", "S·ªØa ƒë·∫∑c"]
    }

    # === ƒê∆°n v·ªã ph√π h·ª£p v·ªõi t·ª´ng danh m·ª•c
    category_units = {
        "ƒê·ªì u·ªëng": ["Chai", "L√≠t", "H·ªôp"],
        "B√°nh k·∫πo": ["G√≥i", "H·ªôp", "C√°i"],
        "Th·ª±c ph·∫©m t∆∞∆°i s·ªëng": ["Kg", "Gram"],
        "Th·ª±c ph·∫©m kh√¥": ["Kg", "G√≥i"],
        "Gia v·ªã": ["Chai", "G√≥i", "Gram"],
        "ƒê·ªì gia d·ª•ng": ["C√°i", "B·ªô"],
        "ChƒÉm s√≥c c√° nh√¢n": ["Chai", "H·ªôp", "Tu√Ωp"],
        "ChƒÉm s√≥c nh√† c·ª≠a": ["Chai", "T√∫i", "H·ªôp"],
        "Th·ª±c ph·∫©m ƒë√¥ng l·∫°nh": ["G√≥i", "H·ªôp", "Kg"],
        "S·ªØa v√† s·∫£n ph·∫©m t·ª´ s·ªØa": ["H·ªôp", "L√≠t", "Chai"]
    }

    ids = next_ids("Products", n)
    data = []

    for pid in ids:
        cat_id = random.choice(category_ids)
        cat_name = category_map.get(cat_id, "Kh√°c")

        # T√™n s·∫£n ph·∫©m theo danh m·ª•c
        keywords = category_keywords.get(cat_name, [fake.word().capitalize()])
        product_name = random.choice(keywords)

        # ƒê∆°n v·ªã ph√π h·ª£p
        possible_units = category_units.get(cat_name, ["C√°i"])
        unit_name = random.choice(possible_units)
        unit_id = unit_map.get(unit_name, random.choice(unit_ids))

        # Th√™m th∆∞∆°ng hi·ªáu ƒë·ªÉ ƒëa d·∫°ng
        brand = fake.company().split()[0]
        full_name = f"{product_name} {brand}"

        data.append({
            "ProductID": pid,
            "ProductName": full_name,
            "CategoryID": cat_id,
            "UnitID": unit_id,
            "StatusID": random.choice(status_ids),
            "Description": fake.sentence(nb_words=10),
            "CreatedDate": fake.date_time_between(start_date="-2y", end_date="now").strftime("%Y-%m-%d %H:%M:%S")
        })

    write_csv(
        os.path.join(OUTPUT_DIR, "Products.csv"),
        fieldnames=list(data[0].keys()),
        data_rows=data
    )

    print(f"[OK] Products ({n} h√†ng)")

```

- Ch·∫°y file main_generate.py ƒë·ªÉ sinh d·ªØ li·ªáu ng·∫´u nhi√™n.
- Code ch∆∞a ƒë∆∞·ª£c t·ªëi ∆∞u n√™n vi·ªác sinh d·ªØ li·ªáu ch·ªâ ƒë·ªß ƒë·ªÉ test Database, nh∆∞ng v·∫´n ƒë·ªß d√πng.

---

## 5. File Control SQL*Loader

products.ctl
```
load data 
characterset AL32UTF8
infile 'Products.csv' "str '\r\n'"
append
into table PRODUCTS
fields terminated by ','
OPTIONALLY ENCLOSED BY '"' AND '"'
trailing nullcols
           ( PRODUCTID,
             PRODUCTNAME CHAR(255),
             CATEGORYID,
             UNITID,
             STATUSID,
             DESCRIPTION CHAR(4000),
             CREATEDDATE TIMESTAMP "YYYY-MM-DD HH24:MI:SS"
           )
```

- C√¢u l·ªánh ch√≠nh: "load data" (b·∫Øt ƒë·∫ßu khai b√°o job load d·ªØ li·ªáu).
- Thi·∫øt l·∫≠p k√Ω t·ª±: "characterset AL32UTF8" (d·ªØ li·ªáu CSV ƒë∆∞·ª£c ƒë·ªçc theo encoding UTF-8 (AL32UTF8)).
- File ngu·ªìn: infile 'Products.csv' "str '\r\n'" (l·∫•y d·ªØ li·ªáu t·ª´ file Products.csv v√† k·∫øt th√∫c m·ªói d√≤ng l√† CRLF (\r\n), ph·ªï bi·∫øn tr√™n Windows).
- H√†nh vi load: "append" (th√™m d·ªØ li·ªáu v√†o b·∫£ng PRODUCTS m√† kh√¥ng x√≥a d·ªØ li·ªáu c≈©).
- ƒê·ªãnh d·∫°ng tr∆∞·ªùng: fields terminated by ',' OPTIONALLY ENCLOSED BY '"' AND '"'
- Mapping c·ªôt:
```
( PRODUCTID,
  PRODUCTNAME CHAR(255),
  CATEGORYID,
  UNITID,
  STATUSID,
  DESCRIPTION CHAR(4000),
  CREATEDDATE TIMESTAMP "YYYY-MM-DD HH24:MI:SS"
)
```

---

## 6. Chuy·ªÉn file sang m√°y ·∫£o

- D√πng tools WinSCP h·ªó tr·ª£ k·∫øt n·ªëi ƒë·∫øn m√°y ·∫£o qua SSH.

## 7. Script th·ª±c thi ETL tr√™n m√°y ·∫£o

run_all_loaders.sh
```bash
#!/bin/bash
# ========================================
# Script: run_all_loaders.sh
# M·ª•c ƒë√≠ch: T·ª± ƒë·ªông ch·∫°y t·∫•t c·∫£ file .ctl trong th∆∞ m·ª•c
# T√°c gi·∫£: Tger
# ========================================

# Th√¥ng tin k·∫øt n·ªëi Oracle
USER="RETAIL_USER"
PASS="retail123"
CONN="localhost:1521/orclpdb"

# T·∫°o file log t·ªïng h·ª£p
MASTER_LOG="all_loader_results_$(date +%Y%m%d_%H%M%S).log"
echo "SQL*Loader batch started at $(date)" > "$MASTER_LOG"
echo "====================================" >> "$MASTER_LOG"

CTL_ORDER=(
  "Branch_Status.ctl"
  "Branch_Types.ctl"
  "Branches.ctl"
  "Branch_Managers.ctl"
  "Branch_Employees.ctl"
  "Employee_Status.ctl"
  "Employee_Types.ctl"
  "Employees.ctl"
  "Employee_Salaries.ctl"
  "Customer_Status.ctl"
  "Customer_Types.ctl"
  "Customers.ctl"
  "Customer_Addresses.ctl"
  "Product_Status.ctl"
  "Product_Categories.ctl"
  "Product_Units.ctl"
  "Products.ctl"
  "Product_Prices.ctl"
  "Order_Status.ctl"
  "Orders.ctl"
  "Order_Details.ctl"
  "Invoice_Status.ctl"
  "Invoices.ctl"
  "Order_Invoices.ctl"
  "Payment_Methods.ctl"
  "Payments.ctl"
  "Sale_Channels.ctl"
  "Sale_Staffs.ctl"
)

for ctl in "${CTL_ORDER[@]}"; do
    base=$(basename "$ctl" .ctl)
    echo "üîπ Loading $base ..." | tee -a "$MASTER_LOG"

    sqlldr userid=${USER}/${PASS}@${CONN} \
    control="$ctl" \
    log="${base}.log" \
    bad="${base}.bad" \
    direct=true

    if [ $? -eq 0 ]; then
        echo "‚úÖ $base loaded successfully." | tee -a "$MASTER_LOG"
    else
        echo "Error loading $base. Check ${base}.log" | tee -a "$MASTER_LOG"
    fi

    echo "------------------------------------" >> "$MASTER_LOG"
done

echo "All loads finished at $(date)" >> "$MASTER_LOG"
echo "See $MASTER_LOG for summary."
```

---

## 8. Ki·ªÉm tra sau khi load

## 8.1. Ki·ªÉm tra s·ªë d√≤ng
```SQL
SELECT COUNT(*) FROM Products;
```

## 8.2. Ki·ªÉm tra log
T√¨m d√≤ng:
- Rows successfully loaded
- Rows rejected

---

## 9. Best Practices

- T√™n file ph·∫£i kh·ªõp: products.csv ‚Üî products.ctl.
- Th·ª© t·ª± n·∫°p ph·∫£i ƒë√∫ng theo th·ª© t·ª± r√†ng bu·ªôc kh√≥a ngo·∫°i.
- D√πng TO_TIMESTAMP() trong .ctl cho c·ªôt th·ªùi gian.
- D√πng Faker.seed() ƒë·ªÉ d·ªØ li·ªáu t√°i t·∫°o b·∫•t k·ª≥ l√∫c n√†o.
- D√πng direct=true parallel=true ƒë·ªÉ tƒÉng t·ªëc load.